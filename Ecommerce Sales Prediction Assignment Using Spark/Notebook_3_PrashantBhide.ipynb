{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Linux\n"
     ]
    }
   ],
   "source": [
    "import os, sys, warnings, platform\n",
    "\n",
    "osname = platform.system()\n",
    "print('Running on', osname)\n",
    "\n",
    "if (osname == 'Windows'):\n",
    "    # Definitions for Windows 10 instance\n",
    "    os.environ[\"PYSPARK_PYTHON\"] = \"D:/Anaconda3/python\"\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"D:/Anaconda3/python\"\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"]=\"notebook --no-browser\"\n",
    "    os.environ[\"JAVA_HOME\"] = \"C:/Program Files/Java/jdk1.8.0_251/jre\"\n",
    "    os.environ[\"SPARK_HOME\"] = \"D:/spark-2.4.4-bin-hadoop2.7\"\n",
    "    os.environ[\"HADOOP_HOME\"] = \"D:/spark-2.4.4-bin-hadoop2.7\"\n",
    "    os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "    sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "    sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "else:\n",
    "    # Definitions for EC2 Linux instance\n",
    "    os.environ[\"PYSPARK_PYTHON\"]=\"/usr/bin/python3\"\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/usr/bin/python3\"\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"]=\"notebook --no-browser\"\n",
    "    os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_161/jre\"\n",
    "    os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/spark-2.4.4-bin-hadoop2.7\"\n",
    "    os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "    sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.7-src.zip\")\n",
    "    sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecommerce Churn Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the assignment is to build a model that predicts whether a person purchases an item after it has been added to the cart or not. Being a classification problem, you are expected to use your understanding of all the three models covered till now. You must select the most robust model and provide a solution that predicts the churn in the most suitable manner. \n",
    "\n",
    "For this assignment, you are provided the data associated with an e-commerce company for the month of October 2019. Your task is to first analyse the data, and then perform multiple steps towards the model building process.\n",
    "\n",
    "The broad tasks are:\n",
    "- Data Exploration\n",
    "- Feature Engineering\n",
    "- Model Selection\n",
    "- Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset stores the information of a customer session on the e-commerce platform. It records the activity and the associated parameters with it.\n",
    "\n",
    "- **event_time**: Date and time when user accesses the platform\n",
    "- **event_type**: Action performed by the customer\n",
    "            - View\n",
    "            - Cart\n",
    "            - Purchase\n",
    "            - Remove from cart\n",
    "- **product_id**: Unique number to identify the product in the event\n",
    "- **category_id**: Unique number to identify the category of the product\n",
    "- **category_code**: Stores primary and secondary categories of the product\n",
    "- **brand**: Brand associated with the product\n",
    "- **price**: Price of the product\n",
    "- **user_id**: Unique ID for a customer\n",
    "- **user_session**: Session ID for a user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset provided is 5 GBs in size. Therefore, it is expected that you increase the driver memory to a greater number. You can refer to notebook 1 for the steps involved here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-67-244.ec2.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Notebook_3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f82a518a290>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "MAX_MEMORY = \"14G\"\n",
    "spark = SparkSession.builder.appName(\"Notebook_3\").config(\"spark.driver.memory\", MAX_MEMORY).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14G'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark session with 14 GB driver memory\n",
    "\n",
    "spark.sparkContext.getConf().get('spark.driver.memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('float_format', '{:.4f}'.format)\n",
    "pd.options.display.max_colwidth = 100\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = '14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed_df row count = 1033889\n",
      "CPU times: user 2.88 ms, sys: 1.48 ms, total: 4.36 ms\n",
      "Wall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loading the clean data\n",
    "\n",
    "df = spark.read.parquet('task3_transformed_df.parquet')\n",
    "print('transformed_df row count =', df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Model Selection\n",
    "3 models for classification:\t\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional steps for Decision Trees, if any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Transformation (Code will be same; check for the columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if only the required columns are present to build the model\n",
    "# If not, drop the redundant columns\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorising the attributes into its type - Continuous and Categorical\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature transformation for categorical features\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector assembler to combine all the features\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for the tasks\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the dataframe df\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- sub_category: string (nullable = true)\n",
      " |-- user_session_activity_count: long (nullable = true)\n",
      " |-- product_count_for_user: long (nullable = true)\n",
      " |-- sub_category_count_for_user: long (nullable = true)\n",
      " |-- avg_expense_for_sub_category: double (nullable = true)\n",
      " |-- user_sessions_count: long (nullable = true)\n",
      " |-- day_quadrant: string (nullable = true)\n",
      " |-- is_purchased: integer (nullable = true)\n",
      " |-- day_of_week_idx: double (nullable = true)\n",
      " |-- day_of_week_enc: vector (nullable = true)\n",
      " |-- day_quadrant_idx: double (nullable = true)\n",
      " |-- day_quadrant_enc: vector (nullable = true)\n",
      " |-- category_idx: double (nullable = true)\n",
      " |-- category_enc: vector (nullable = true)\n",
      " |-- sub_category_idx: double (nullable = true)\n",
      " |-- sub_category_enc: vector (nullable = true)\n",
      " |-- brand_idx: double (nullable = true)\n",
      " |-- brand_enc: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "CPU times: user 1.36 ms, sys: 691 µs, total: 2.06 ms\n",
      "Wall time: 8.77 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Schema of the transformed df\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+------------+------------+---------------------------+----------------------+---------------------------+----------------------------+-------------------+------------+------------+---------------+---------------+----------------+----------------+------------+--------------+----------------+----------------+---------+--------------+--------------------+\n",
      "|  brand|  price|day_of_week|    category|sub_category|user_session_activity_count|product_count_for_user|sub_category_count_for_user|avg_expense_for_sub_category|user_sessions_count|day_quadrant|is_purchased|day_of_week_idx|day_of_week_enc|day_quadrant_idx|day_quadrant_enc|category_idx|  category_enc|sub_category_idx|sub_category_enc|brand_idx|     brand_enc|            features|\n",
      "+-------+-------+-----------+------------+------------+---------------------------+----------------------+---------------------------+----------------------------+-------------------+------------+------------+---------------+---------------+----------------+----------------+------------+--------------+----------------+----------------+---------+--------------+--------------------+\n",
      "|samsung| 131.51|      5-Thu| electronics|  smartphone|                          3|                     3|                          3|                      131.51|                  1| 2-Afternoon|           1|            3.0|  (6,[3],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      1.0|(20,[1],[1.0])|(104,[3,6,9,22,79...|\n",
      "|  apple| 460.11|      4-Wed| electronics|  smartphone|                          8|                     4|                          8|                   353.42125|                  1|   3-Evening|           1|            0.0|  (6,[0],[1.0])|             1.0|   (3,[1],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      2.0|(20,[2],[1.0])|(104,[0,7,9,22,80...|\n",
      "|samsung| 287.63|      4-Wed| electronics|  smartphone|                          9|                     6|                         39|            215.765641025641|                 26|   3-Evening|           1|            0.0|  (6,[0],[1.0])|             1.0|   (3,[1],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      1.0|(20,[1],[1.0])|(104,[0,7,9,22,79...|\n",
      "|samsung| 224.96|      5-Thu| electronics|  smartphone|                          7|                     7|                         16|          227.93125000000003|                  6|   3-Evening|           0|            3.0|  (6,[3],[1.0])|             1.0|   (3,[1],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      1.0|(20,[1],[1.0])|(104,[3,7,9,22,79...|\n",
      "|  apple| 295.75|      5-Thu| electronics|      clocks|                          2|                    12|                         18|          222.25555555555553|                  8| 2-Afternoon|           1|            3.0|  (6,[3],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             6.0|  (56,[6],[1.0])|      2.0|(20,[2],[1.0])|(104,[3,6,9,28,80...|\n",
      "|  apple| 975.56|      1-Sun| electronics|  smartphone|                          7|                     4|                          4|                      975.56|                  1| 2-Afternoon|           0|            4.0|  (6,[4],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      2.0|(20,[2],[1.0])|(104,[4,6,9,22,80...|\n",
      "| others|  55.86|      6-Fri|     unknown|     unknown|                          2|                     2|                        112|          157.77562499999993|                104|   3-Evening|           1|            2.0|  (6,[2],[1.0])|             1.0|   (3,[1],[1.0])|         1.0|(13,[1],[1.0])|             1.0|  (56,[1],[1.0])|      0.0|(20,[0],[1.0])|(104,[2,7,10,23,7...|\n",
      "| others| 527.39|      3-Tue|  appliances|     kitchen|                          2|                     2|                          2|                      527.39|                  1| 2-Afternoon|           0|            1.0|  (6,[1],[1.0])|             0.0|   (3,[0],[1.0])|         2.0|(13,[2],[1.0])|             2.0|  (56,[2],[1.0])|      0.0|(20,[0],[1.0])|(104,[1,6,11,24,7...|\n",
      "| xiaomi|  28.55|      7-Sat|     unknown|     unknown|                          9|                    42|                         43|           28.92953488372092|                 11|   3-Evening|           1|            5.0|  (6,[5],[1.0])|             1.0|   (3,[1],[1.0])|         1.0|(13,[1],[1.0])|             1.0|  (56,[1],[1.0])|      3.0|(20,[3],[1.0])|(104,[5,7,10,23,8...|\n",
      "|  apple|  190.2|      3-Tue| electronics|       audio|                          5|                     4|                         22|            86.5059090909091|                 13| 2-Afternoon|           1|            1.0|  (6,[1],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             3.0|  (56,[3],[1.0])|      2.0|(20,[2],[1.0])|(104,[1,6,9,25,80...|\n",
      "|  apple| 160.61|      5-Thu| electronics|       audio|                          8|                    11|                         11|          160.61000000000004|                  6|   1-Morning|           1|            3.0|  (6,[3],[1.0])|             2.0|   (3,[2],[1.0])|         0.0|(13,[0],[1.0])|             3.0|  (56,[3],[1.0])|      2.0|(20,[2],[1.0])|(104,[3,8,9,25,80...|\n",
      "| others|  53.72|      5-Thu| electronics|   telephone|                          6|                     6|                          6|          53.720000000000006|                 13| 2-Afternoon|           0|            3.0|  (6,[3],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|            13.0| (56,[13],[1.0])|      0.0|(20,[0],[1.0])|(104,[3,6,9,35,78...|\n",
      "|samsung|  369.2|      5-Thu| electronics|  smartphone|                          5|                     9|                         40|          278.95574999999997|                  8| 2-Afternoon|           1|            3.0|  (6,[3],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      1.0|(20,[1],[1.0])|(104,[3,6,9,22,79...|\n",
      "| others|  72.05|      7-Sat|construction|       tools|                         17|                     5|                         12|          105.99000000000001|                  8| 2-Afternoon|           1|            5.0|  (6,[5],[1.0])|             0.0|   (3,[0],[1.0])|         5.0|(13,[5],[1.0])|             9.0|  (56,[9],[1.0])|      0.0|(20,[0],[1.0])|(104,[5,6,14,31,7...|\n",
      "|samsung| 286.86|      3-Tue| electronics|  smartphone|                          2|                     2|                          6|                      165.87|                  2| 2-Afternoon|           1|            1.0|  (6,[1],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      1.0|(20,[1],[1.0])|(104,[1,6,9,22,79...|\n",
      "|  apple|  159.8|      3-Tue| electronics|       audio|                         13|                    14|                         18|           169.9061111111111|                  2|   3-Evening|           0|            1.0|  (6,[1],[1.0])|             1.0|   (3,[1],[1.0])|         0.0|(13,[0],[1.0])|             3.0|  (56,[3],[1.0])|      2.0|(20,[2],[1.0])|(104,[1,7,9,25,80...|\n",
      "|  apple|1415.48|      4-Wed| electronics|  smartphone|                          7|                     3|                          8|                    1207.655|                  3|   1-Morning|           0|            0.0|  (6,[0],[1.0])|             2.0|   (3,[2],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      2.0|(20,[2],[1.0])|(104,[0,8,9,22,80...|\n",
      "| others| 1044.4|      4-Wed| electronics|      clocks|                          7|                    13|                         42|           1032.974761904762|                  3|   3-Evening|           0|            0.0|  (6,[0],[1.0])|             1.0|   (3,[1],[1.0])|         0.0|(13,[0],[1.0])|             6.0|  (56,[6],[1.0])|      0.0|(20,[0],[1.0])|(104,[0,7,9,28,78...|\n",
      "| others| 121.24|      2-Mon|        auto| accessories|                         13|                     7|                        122|           92.88385245901638|                 20|   3-Evening|           1|            6.0|      (6,[],[])|             1.0|   (3,[1],[1.0])|         4.0|(13,[4],[1.0])|             8.0|  (56,[8],[1.0])|      0.0|(20,[0],[1.0])|(104,[7,13,30,78,...|\n",
      "|samsung| 371.67|      1-Sun| electronics|  smartphone|                          5|                    11|                        109|            477.136605504587|                 45| 2-Afternoon|           1|            4.0|  (6,[4],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      1.0|(20,[1],[1.0])|(104,[4,6,9,22,79...|\n",
      "+-------+-------+-----------+------------+------------+---------------------------+----------------------+---------------------------+----------------------------+-------------------+------------+------------+---------------+---------------+----------------+----------------+------------+--------------+----------------+----------------+---------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 2.68 ms, sys: 0 ns, total: 2.68 ms\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Checking the elements of the transformed df - Top 20 rows\n",
    "\n",
    "df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the transformed df in S3 bucket to prevent repetition of steps again\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.3 ms, sys: 1.16 ms, total: 3.46 ms\n",
      "Wall time: 25.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Splitting the data into train and test (Remember you are expected to compare the model later)\n",
    "\n",
    "df_train, df_test = df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Count: 723091 | Test Dataset Count: 310798\n",
      "CPU times: user 5.21 ms, sys: 2.35 ms, total: 7.56 ms\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Number of rows in train and test data\n",
    "\n",
    "print('Train Dataset Count:', df_train.count(), '| Test Dataset Count:', df_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 164 ms, sys: 3.58 ms, total: 167 ms\n",
      "Wall time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Building the model with hyperparameter tuning\n",
    "# Create ParamGrid for Cross Validation\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='is_purchased', seed=42)\n",
    "\n",
    "dtParamGrid = ParamGridBuilder() \\\n",
    "              .addGrid(dt.maxDepth, [10,20,30]) \\\n",
    "              .addGrid(dt.maxBins, [5,10,15]) \\\n",
    "              .build()\n",
    "\n",
    "dtEvaluator = BinaryClassificationEvaluator(labelCol='is_purchased')\n",
    "\n",
    "multiEvaluator = MulticlassClassificationEvaluator(labelCol='is_purchased', predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 339 µs, sys: 0 ns, total: 339 µs\n",
      "Wall time: 327 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run cross-validation steps\n",
    "\n",
    "crossval = CrossValidator(estimator=dt, estimatorParamMaps=dtParamGrid, evaluator=dtEvaluator, numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 s, sys: 715 ms, total: 2.4 s\n",
      "Wall time: 21min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fitting the models on transformed df\n",
    "\n",
    "cvModel = crossval.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 µs, sys: 0 ns, total: 19 µs\n",
      "Wall time: 24.1 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_a7a731a0d45c) of depth 30 with 374963 nodes"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Best model from the results of cross-validation\n",
    "\n",
    "dtBestModel = cvModel.bestModel\n",
    "dtBestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Steps:\n",
    "- Fit on test data\n",
    "- Performance analysis\n",
    "    - Appropriate Metric with reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.67 ms, sys: 2.12 ms, total: 8.79 ms\n",
      "Wall time: 62.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = dtBestModel.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data Accuracy = 0.8785352544096166\n",
      "CPU times: user 22.9 ms, sys: 10.1 ms, total: 33 ms\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multiEvaluator.setMetricName('accuracy')\n",
    "accuracy = multiEvaluator.evaluate(predictions)\n",
    "print('Test data Accuracy =', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data Precision = 0.8790522005363621\n",
      "CPU times: user 29.5 ms, sys: 12.1 ms, total: 41.5 ms\n",
      "Wall time: 50.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multiEvaluator.setMetricName('weightedPrecision')\n",
    "precision = multiEvaluator.evaluate(predictions)\n",
    "print('Test data Precision =', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data Recall = 0.8785352544096166\n",
      "CPU times: user 26.1 ms, sys: 5.79 ms, total: 31.9 ms\n",
      "Wall time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multiEvaluator.setMetricName('weightedRecall')\n",
    "recall = multiEvaluator.evaluate(predictions)\n",
    "print('Test data Recall =', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data F1_score = 0.8787936514502295\n"
     ]
    }
   ],
   "source": [
    "F1_score = (2 * precision * recall) / (precision + recall)\n",
    "print('Test data F1_score =', F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data ROC_AUC = 0.7396132709059026\n",
      "CPU times: user 13.2 ms, sys: 5.73 ms, total: 18.9 ms\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "areaUnderROC = dtEvaluator.evaluate(predictions, {dtEvaluator.metricName: 'areaUnderROC'})\n",
    "print('Test data ROC_AUC =', areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of the best Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to extract features along with the feature importance score\n",
    "\n",
    "import pandas as pd\n",
    "def ExtractFeatureImp(featureImp, dataset, featuresCol):\n",
    "    list_extract = []\n",
    "    for i in dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "        list_extract = list_extract + dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "    varlist = pd.DataFrame(list_extract)\n",
    "    varlist['score'] = varlist['idx'].apply(lambda x: featureImp[x])\n",
    "    return(varlist.sort_values('score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.9 ms, sys: 0 ns, total: 7.9 ms\n",
      "Wall time: 10.3 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>103</td>\n",
       "      <td>user_sessions_count</td>\n",
       "      <td>0.1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>product_count_for_user</td>\n",
       "      <td>0.1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>sub_category_count_for_user</td>\n",
       "      <td>0.1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>price</td>\n",
       "      <td>0.1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>user_session_activity_count</td>\n",
       "      <td>0.0913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                         name  score\n",
       "5  103          user_sessions_count 0.1235\n",
       "2  100       product_count_for_user 0.1071\n",
       "3  101  sub_category_count_for_user 0.1069\n",
       "0   98                        price 0.1055\n",
       "1   99  user_session_activity_count 0.0913"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Printing the feature importance scores\n",
    "\n",
    "dtFeatureImp = ExtractFeatureImp(dtBestModel.featureImportances, predictions, 'features')\n",
    "dtFeatureImp.to_csv('decisionTreeFeatureImp.csv')\n",
    "dtFeatureImp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Based on the DecisionTree featureImportance scores, we can see that the top 5 important features for predicting the \"purchase\" target variable are:*__\n",
    "1. user_sessions_count\n",
    "2. product_count_for_user\n",
    "3. sub_category_count_for_user\n",
    "4. price\n",
    "5. user_session_activity_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree depth of the best model = 30\n"
     ]
    }
   ],
   "source": [
    "print('Tree depth of the best model =', dtBestModel.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features used by the best model = 104\n"
     ]
    }
   ],
   "source": [
    "print('Number of features used by the best model =', dtBestModel.numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the best model = 374963\n"
     ]
    }
   ],
   "source": [
    "print('Number of nodes in the best model =', dtBestModel.numNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ModelType</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AreaUnderROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.7396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ModelType  Accuracy  Precision  Recall  F1_score  AreaUnderROC\n",
       "0  DecisionTree    0.8785     0.8791  0.8785    0.8788        0.7396"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collate all the model evaluation metrics\n",
    "decisionTreeMetrics = [{'ModelType'    : 'DecisionTree',\n",
    "                        'Accuracy'     : accuracy,\n",
    "                        'Precision'    : precision,\n",
    "                        'Recall'       : recall,\n",
    "                        'F1_score'     : F1_score,\n",
    "                        'AreaUnderROC' : areaUnderROC}]\n",
    "  \n",
    "# Convert the metrics to a Pandas dataframe \n",
    "decisionTreeMetrics_df = pd.DataFrame(decisionTreeMetrics)\n",
    "\n",
    "# Save the dataframe as csv for future model comparison\n",
    "decisionTreeMetrics_df.to_csv('decisionTreeMetrics.csv')\n",
    "\n",
    "decisionTreeMetrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics for the best DecisionTree Model :\n",
    "1. Accuracy = 0.8785352544096166<br>\n",
    "2. Precision = 0.8790522005363621<br>\n",
    "3. Recall = 0.8785352544096166<br>\n",
    "4. F1_score = 0.8787936514502295<br>\n",
    "5. AreaUnderROC = 0.7396132709059026<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
