{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Linux\n"
     ]
    }
   ],
   "source": [
    "import os, sys, warnings, platform\n",
    "\n",
    "osname = platform.system()\n",
    "print('Running on', osname)\n",
    "\n",
    "if (osname == 'Windows'):\n",
    "    # Definitions for Windows 10 instance\n",
    "    os.environ[\"PYSPARK_PYTHON\"] = \"D:/Anaconda3/python\"\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"D:/Anaconda3/python\"\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"]=\"notebook --no-browser\"\n",
    "    os.environ[\"JAVA_HOME\"] = \"C:/Program Files/Java/jdk1.8.0_251/jre\"\n",
    "    os.environ[\"SPARK_HOME\"] = \"D:/spark-2.4.4-bin-hadoop2.7\"\n",
    "    os.environ[\"HADOOP_HOME\"] = \"D:/spark-2.4.4-bin-hadoop2.7\"\n",
    "    os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "    sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "    sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "else:\n",
    "    # Definitions for EC2 Linux instance\n",
    "    os.environ[\"PYSPARK_PYTHON\"]=\"/usr/bin/python3\"\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/usr/bin/python3\"\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"]=\"notebook --no-browser\"\n",
    "    os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_161/jre\"\n",
    "    os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/spark-2.4.4-bin-hadoop2.7\"\n",
    "    os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "    sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.7-src.zip\")\n",
    "    sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecommerce Churn Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the assignment is to build a model that predicts whether a person purchases an item after it has been added to the cart or not. Being a classification problem, you are expected to use your understanding of all the three models covered till now. You must select the most robust model and provide a solution that predicts the churn in the most suitable manner. \n",
    "\n",
    "For this assignment, you are provided the data associated with an e-commerce company for the month of October 2019. Your task is to first analyse the data, and then perform multiple steps towards the model building process.\n",
    "\n",
    "The broad tasks are:\n",
    "- Data Exploration\n",
    "- Feature Engineering\n",
    "- Model Selection\n",
    "- Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset stores the information of a customer session on the e-commerce platform. It records the activity and the associated parameters with it.\n",
    "\n",
    "- **event_time**: Date and time when user accesses the platform\n",
    "- **event_type**: Action performed by the customer\n",
    "            - View\n",
    "            - Cart\n",
    "            - Purchase\n",
    "            - Remove from cart\n",
    "- **product_id**: Unique number to identify the product in the event\n",
    "- **category_id**: Unique number to identify the category of the product\n",
    "- **category_code**: Stores primary and secondary categories of the product\n",
    "- **brand**: Brand associated with the product\n",
    "- **price**: Price of the product\n",
    "- **user_id**: Unique ID for a customer\n",
    "- **user_session**: Session ID for a user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset provided is 5 GBs in size. Therefore, it is expected that you increase the driver memory to a greater number. You can refer to notebook 1 for the steps involved here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-67-244.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Notebook_4</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f459646d190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "MAX_MEMORY = \"40G\"\n",
    "spark = SparkSession.builder.appName(\"Notebook_4\").config(\"spark.driver.memory\", MAX_MEMORY).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40G'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark session with 40 GB driver memory\n",
    "\n",
    "spark.sparkContext.getConf().get('spark.driver.memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('float_format', '{:.4f}'.format)\n",
    "pd.options.display.max_colwidth = 100\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = '14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed_df row count = 1033889\n",
      "CPU times: user 2.24 ms, sys: 1.71 ms, total: 3.95 ms\n",
      "Wall time: 3.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loading the clean data\n",
    "\n",
    "df = spark.read.parquet('task3_transformed_df.parquet')\n",
    "print('transformed_df row count =', df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Model Selection\n",
    "3 models for classification:\t\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional steps for Random Forest, if any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Transformation (Code will be same; check for the columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if only the required columns are present to build the model\n",
    "# If not, drop the redundant columns\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorising the attributes into its type - Continuous and Categorical\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature transformation for categorical features\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector assembler to combine all the features\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for the tasks\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the dataframe df\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- sub_category: string (nullable = true)\n",
      " |-- user_session_activity_count: long (nullable = true)\n",
      " |-- product_count_for_user: long (nullable = true)\n",
      " |-- sub_category_count_for_user: long (nullable = true)\n",
      " |-- avg_expense_for_sub_category: double (nullable = true)\n",
      " |-- user_sessions_count: long (nullable = true)\n",
      " |-- day_quadrant: string (nullable = true)\n",
      " |-- is_purchased: integer (nullable = true)\n",
      " |-- day_of_week_idx: double (nullable = true)\n",
      " |-- day_of_week_enc: vector (nullable = true)\n",
      " |-- day_quadrant_idx: double (nullable = true)\n",
      " |-- day_quadrant_enc: vector (nullable = true)\n",
      " |-- category_idx: double (nullable = true)\n",
      " |-- category_enc: vector (nullable = true)\n",
      " |-- sub_category_idx: double (nullable = true)\n",
      " |-- sub_category_enc: vector (nullable = true)\n",
      " |-- brand_idx: double (nullable = true)\n",
      " |-- brand_enc: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "CPU times: user 1.09 ms, sys: 828 µs, total: 1.92 ms\n",
      "Wall time: 9.72 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Schema of the transformed df\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+------------+------------+---------------------------+----------------------+---------------------------+----------------------------+-------------------+------------+------------+---------------+---------------+----------------+----------------+------------+--------------+----------------+----------------+---------+--------------+--------------------+\n",
      "|  brand|  price|day_of_week|    category|sub_category|user_session_activity_count|product_count_for_user|sub_category_count_for_user|avg_expense_for_sub_category|user_sessions_count|day_quadrant|is_purchased|day_of_week_idx|day_of_week_enc|day_quadrant_idx|day_quadrant_enc|category_idx|  category_enc|sub_category_idx|sub_category_enc|brand_idx|     brand_enc|            features|\n",
      "+-------+-------+-----------+------------+------------+---------------------------+----------------------+---------------------------+----------------------------+-------------------+------------+------------+---------------+---------------+----------------+----------------+------------+--------------+----------------+----------------+---------+--------------+--------------------+\n",
      "|samsung| 131.51|      5-Thu| electronics|  smartphone|                          3|                     3|                          3|                      131.51|                  1| 2-Afternoon|           1|            3.0|  (6,[3],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      1.0|(20,[1],[1.0])|(104,[3,6,9,22,79...|\n",
      "|  apple| 460.11|      4-Wed| electronics|  smartphone|                          8|                     4|                          8|                   353.42125|                  1|   3-Evening|           1|            0.0|  (6,[0],[1.0])|             1.0|   (3,[1],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      2.0|(20,[2],[1.0])|(104,[0,7,9,22,80...|\n",
      "|samsung| 287.63|      4-Wed| electronics|  smartphone|                          9|                     6|                         39|            215.765641025641|                 26|   3-Evening|           1|            0.0|  (6,[0],[1.0])|             1.0|   (3,[1],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      1.0|(20,[1],[1.0])|(104,[0,7,9,22,79...|\n",
      "|samsung| 224.96|      5-Thu| electronics|  smartphone|                          7|                     7|                         16|          227.93125000000003|                  6|   3-Evening|           0|            3.0|  (6,[3],[1.0])|             1.0|   (3,[1],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      1.0|(20,[1],[1.0])|(104,[3,7,9,22,79...|\n",
      "|  apple| 295.75|      5-Thu| electronics|      clocks|                          2|                    12|                         18|          222.25555555555553|                  8| 2-Afternoon|           1|            3.0|  (6,[3],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             6.0|  (56,[6],[1.0])|      2.0|(20,[2],[1.0])|(104,[3,6,9,28,80...|\n",
      "|  apple| 975.56|      1-Sun| electronics|  smartphone|                          7|                     4|                          4|                      975.56|                  1| 2-Afternoon|           0|            4.0|  (6,[4],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      2.0|(20,[2],[1.0])|(104,[4,6,9,22,80...|\n",
      "| others|  55.86|      6-Fri|     unknown|     unknown|                          2|                     2|                        112|          157.77562499999993|                104|   3-Evening|           1|            2.0|  (6,[2],[1.0])|             1.0|   (3,[1],[1.0])|         1.0|(13,[1],[1.0])|             1.0|  (56,[1],[1.0])|      0.0|(20,[0],[1.0])|(104,[2,7,10,23,7...|\n",
      "| others| 527.39|      3-Tue|  appliances|     kitchen|                          2|                     2|                          2|                      527.39|                  1| 2-Afternoon|           0|            1.0|  (6,[1],[1.0])|             0.0|   (3,[0],[1.0])|         2.0|(13,[2],[1.0])|             2.0|  (56,[2],[1.0])|      0.0|(20,[0],[1.0])|(104,[1,6,11,24,7...|\n",
      "| xiaomi|  28.55|      7-Sat|     unknown|     unknown|                          9|                    42|                         43|           28.92953488372092|                 11|   3-Evening|           1|            5.0|  (6,[5],[1.0])|             1.0|   (3,[1],[1.0])|         1.0|(13,[1],[1.0])|             1.0|  (56,[1],[1.0])|      3.0|(20,[3],[1.0])|(104,[5,7,10,23,8...|\n",
      "|  apple|  190.2|      3-Tue| electronics|       audio|                          5|                     4|                         22|            86.5059090909091|                 13| 2-Afternoon|           1|            1.0|  (6,[1],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             3.0|  (56,[3],[1.0])|      2.0|(20,[2],[1.0])|(104,[1,6,9,25,80...|\n",
      "|  apple| 160.61|      5-Thu| electronics|       audio|                          8|                    11|                         11|          160.61000000000004|                  6|   1-Morning|           1|            3.0|  (6,[3],[1.0])|             2.0|   (3,[2],[1.0])|         0.0|(13,[0],[1.0])|             3.0|  (56,[3],[1.0])|      2.0|(20,[2],[1.0])|(104,[3,8,9,25,80...|\n",
      "| others|  53.72|      5-Thu| electronics|   telephone|                          6|                     6|                          6|          53.720000000000006|                 13| 2-Afternoon|           0|            3.0|  (6,[3],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|            13.0| (56,[13],[1.0])|      0.0|(20,[0],[1.0])|(104,[3,6,9,35,78...|\n",
      "|samsung|  369.2|      5-Thu| electronics|  smartphone|                          5|                     9|                         40|          278.95574999999997|                  8| 2-Afternoon|           1|            3.0|  (6,[3],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      1.0|(20,[1],[1.0])|(104,[3,6,9,22,79...|\n",
      "| others|  72.05|      7-Sat|construction|       tools|                         17|                     5|                         12|          105.99000000000001|                  8| 2-Afternoon|           1|            5.0|  (6,[5],[1.0])|             0.0|   (3,[0],[1.0])|         5.0|(13,[5],[1.0])|             9.0|  (56,[9],[1.0])|      0.0|(20,[0],[1.0])|(104,[5,6,14,31,7...|\n",
      "|samsung| 286.86|      3-Tue| electronics|  smartphone|                          2|                     2|                          6|                      165.87|                  2| 2-Afternoon|           1|            1.0|  (6,[1],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      1.0|(20,[1],[1.0])|(104,[1,6,9,22,79...|\n",
      "|  apple|  159.8|      3-Tue| electronics|       audio|                         13|                    14|                         18|           169.9061111111111|                  2|   3-Evening|           0|            1.0|  (6,[1],[1.0])|             1.0|   (3,[1],[1.0])|         0.0|(13,[0],[1.0])|             3.0|  (56,[3],[1.0])|      2.0|(20,[2],[1.0])|(104,[1,7,9,25,80...|\n",
      "|  apple|1415.48|      4-Wed| electronics|  smartphone|                          7|                     3|                          8|                    1207.655|                  3|   1-Morning|           0|            0.0|  (6,[0],[1.0])|             2.0|   (3,[2],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      2.0|(20,[2],[1.0])|(104,[0,8,9,22,80...|\n",
      "| others| 1044.4|      4-Wed| electronics|      clocks|                          7|                    13|                         42|           1032.974761904762|                  3|   3-Evening|           0|            0.0|  (6,[0],[1.0])|             1.0|   (3,[1],[1.0])|         0.0|(13,[0],[1.0])|             6.0|  (56,[6],[1.0])|      0.0|(20,[0],[1.0])|(104,[0,7,9,28,78...|\n",
      "| others| 121.24|      2-Mon|        auto| accessories|                         13|                     7|                        122|           92.88385245901638|                 20|   3-Evening|           1|            6.0|      (6,[],[])|             1.0|   (3,[1],[1.0])|         4.0|(13,[4],[1.0])|             8.0|  (56,[8],[1.0])|      0.0|(20,[0],[1.0])|(104,[7,13,30,78,...|\n",
      "|samsung| 371.67|      1-Sun| electronics|  smartphone|                          5|                    11|                        109|            477.136605504587|                 45| 2-Afternoon|           1|            4.0|  (6,[4],[1.0])|             0.0|   (3,[0],[1.0])|         0.0|(13,[0],[1.0])|             0.0|  (56,[0],[1.0])|      1.0|(20,[1],[1.0])|(104,[4,6,9,22,79...|\n",
      "+-------+-------+-----------+------------+------------+---------------------------+----------------------+---------------------------+----------------------------+-------------------+------------+------------+---------------+---------------+----------------+----------------+------------+--------------+----------------+----------------+---------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 1.58 ms, sys: 1.2 ms, total: 2.78 ms\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Checking the elements of the transformed df - Top 20 rows\n",
    "\n",
    "df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the transformed df in S3 bucket to prevent repetition of steps again\n",
    "\n",
    "# This step is already completed as part of Notebook_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 ms, sys: 1.22 ms, total: 2.82 ms\n",
      "Wall time: 23.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Splitting the data into train and test (Remember you are expected to compare the model later)\n",
    "\n",
    "df_train, df_test = df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Count: 723091 | Test Dataset Count: 310798\n",
      "CPU times: user 5.17 ms, sys: 3.92 ms, total: 9.09 ms\n",
      "Wall time: 28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Number of rows in train and test data\n",
    "\n",
    "print('Train Dataset Count:', df_train.count(), '| Test Dataset Count:', df_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 166 ms, sys: 5.27 ms, total: 171 ms\n",
      "Wall time: 169 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Building the model with hyperparameter tuning\n",
    "# Create ParamGrid for Cross Validation\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.04 ms, sys: 819 µs, total: 2.86 ms\n",
      "Wall time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Considering the EC2 instance model performance and processing time constraints,\n",
    "# Pre-setting most of the RandomForestClassifier hyperparameters based on results from earlier DecisionTree model,\n",
    "# And keeping just ['impurity'='gini' or 'entropy'] as the ParamGrid variable value\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='is_purchased', maxDepth=30, maxBins=15, numTrees=10, seed=42)\n",
    "rf\n",
    "\n",
    "rfParamGrid = ParamGridBuilder() \\\n",
    "              .addGrid(rf.impurity, ['gini','entropy']) \\\n",
    "              .build()\n",
    "\n",
    "rfEvaluator = BinaryClassificationEvaluator(labelCol='is_purchased')\n",
    "\n",
    "multiEvaluator = MulticlassClassificationEvaluator(labelCol='is_purchased', predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 368 µs, sys: 0 ns, total: 368 µs\n",
      "Wall time: 355 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run cross-validation steps\n",
    "\n",
    "crossval = CrossValidator(estimator=rf, estimatorParamMaps=rfParamGrid, evaluator=rfEvaluator, numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.89 s, sys: 736 ms, total: 2.63 s\n",
      "Wall time: 34min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fitting the models on transformed df\n",
    "\n",
    "cvModel = crossval.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassificationModel (uid=RandomForestClassifier_5f491d09dcb5) with 10 trees"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model from the results of cross-validation\n",
    "\n",
    "rfBestModel = cvModel.bestModel\n",
    "rfBestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Steps:\n",
    "- Fit on test data\n",
    "- Performance analysis\n",
    "    - Appropriate Metric with reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.36 ms, sys: 5.66 ms, total: 9.02 ms\n",
      "Wall time: 60.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = rfBestModel.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data Accuracy = 0.7175046171468284\n",
      "CPU times: user 32 ms, sys: 9.51 ms, total: 41.5 ms\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multiEvaluator.setMetricName('accuracy')\n",
    "accuracy = multiEvaluator.evaluate(predictions)\n",
    "print('Test data Accuracy =', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data Precision = 0.7223446670705886\n",
      "CPU times: user 41.4 ms, sys: 16.4 ms, total: 57.8 ms\n",
      "Wall time: 50.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multiEvaluator.setMetricName('weightedPrecision')\n",
    "precision = multiEvaluator.evaluate(predictions)\n",
    "print('Test data Precision =', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data Recall = 0.7175046171468284\n",
      "CPU times: user 35.2 ms, sys: 10.6 ms, total: 45.8 ms\n",
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multiEvaluator.setMetricName('weightedRecall')\n",
    "recall = multiEvaluator.evaluate(predictions)\n",
    "print('Test data Recall =', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data F1_score = 0.7199165072005896\n"
     ]
    }
   ],
   "source": [
    "F1_score = (2 * precision * recall) / (precision + recall)\n",
    "print('Test data F1_score =', F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data ROC_AUC = 0.7299482874299179\n",
      "CPU times: user 18.6 ms, sys: 7.38 ms, total: 26 ms\n",
      "Wall time: 18.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "areaUnderROC = rfEvaluator.evaluate(predictions, {rfEvaluator.metricName: 'areaUnderROC'})\n",
    "print('Test data ROC_AUC =', areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of the best Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to extract features along with the feature importance score\n",
    "\n",
    "import pandas as pd\n",
    "def ExtractFeatureImp(featureImp, dataset, featuresCol):\n",
    "    list_extract = []\n",
    "    for i in dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "        list_extract = list_extract + dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "    varlist = pd.DataFrame(list_extract)\n",
    "    varlist['score'] = varlist['idx'].apply(lambda x: featureImp[x])\n",
    "    return(varlist.sort_values('score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 8.08 ms, total: 8.08 ms\n",
      "Wall time: 10.7 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>user_session_activity_count</td>\n",
       "      <td>0.1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>product_count_for_user</td>\n",
       "      <td>0.1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>price</td>\n",
       "      <td>0.0624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>sub_category_count_for_user</td>\n",
       "      <td>0.0609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>avg_expense_for_sub_category</td>\n",
       "      <td>0.0608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                          name  score\n",
       "1   99   user_session_activity_count 0.1173\n",
       "2  100        product_count_for_user 0.1097\n",
       "0   98                         price 0.0624\n",
       "3  101   sub_category_count_for_user 0.0609\n",
       "4  102  avg_expense_for_sub_category 0.0608"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Printing the feature importance scores\n",
    "\n",
    "rfFeatureImp = ExtractFeatureImp(rfBestModel.featureImportances, predictions, 'features').head(5)\n",
    "rfFeatureImp.to_csv('randomForestFeatureImp.csv')\n",
    "rfFeatureImp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Based on the RandomForest featureImportance scores, we see that the top 5 important features for predicting the \"purchase\" target variable are:*__\n",
    "1. user_session_activity_count\n",
    "2. product_count_for_user\n",
    "3. price\n",
    "4. sub_category_count_for_user\n",
    "5. avg_expense_for_sub_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features used by the best model = 104\n"
     ]
    }
   ],
   "source": [
    "print('Number of features used by the best model =', rfBestModel.numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the best model = 226646\n"
     ]
    }
   ],
   "source": [
    "print('Number of nodes in the best model =', rfBestModel.totalNumNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassificationModel (uid=dtc_185cfc2c8b7a) of depth 30 with 19459 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_78844dbf8df5) of depth 30 with 31475 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_7c5c3ae97171) of depth 30 with 17313 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_3b24764493a3) of depth 30 with 22229 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_861fb84ce010) of depth 30 with 19245 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_f2a8b9048909) of depth 30 with 18747 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_e3ba3c78001c) of depth 30 with 15511 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_bae43bf50e46) of depth 30 with 27941 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_0b838e577a74) of depth 30 with 32125 nodes,\n",
       " DecisionTreeClassificationModel (uid=dtc_e8f8d0f87be7) of depth 30 with 22601 nodes]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfBestModel.trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ModelType</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AreaUnderROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>0.7199</td>\n",
       "      <td>0.7299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ModelType  Accuracy  Precision  Recall  F1_score  AreaUnderROC\n",
       "0  RandomForest    0.7175     0.7223  0.7175    0.7199        0.7299"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collate all the model evaluation metrics\n",
    "randomForestMetrics = [{'ModelType'    : 'RandomForest',\n",
    "                        'Accuracy'     : accuracy,\n",
    "                        'Precision'    : precision,\n",
    "                        'Recall'       : recall,\n",
    "                        'F1_score'     : F1_score,\n",
    "                        'AreaUnderROC' : areaUnderROC}]\n",
    "  \n",
    "# Convert the metrics to a Pandas dataframe \n",
    "randomForestMetrics_df = pd.DataFrame(randomForestMetrics)\n",
    "\n",
    "# Save the dataframe as csv for future model comparison\n",
    "randomForestMetrics_df.to_csv('randomForestMetrics.csv')\n",
    "\n",
    "randomForestMetrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics for the best RandomForestClassifier Model :\n",
    "1. Accuracy = 0.7175046171468284<br>\n",
    "2. Precision = 0.7223446670705886<br>\n",
    "3. Recall = 0.7175046171468284<br>\n",
    "4. F1_score = 0.7199165072005896<br>\n",
    "5. AreaUnderROC = 0.7299482874299179<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
